{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 28, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/prabe/Desktop/credit_card_fraud_detection/pages/api/predict.ts"],"sourcesContent":["import type { NextApiRequest, NextApiResponse } from \"next\";\r\nimport path from \"path\";\r\nimport { spawnSync } from \"child_process\";\r\nimport fs from \"fs\";\r\n\r\n// Your server-side Gemini key\r\nconst GEMINI_API_KEY = process.env.GEMINI_KEY;\r\n\r\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\r\n  if (req.method !== \"POST\") return res.status(405).end();\r\n\r\n  try {\r\n    const { features } = req.body; // expect array of 30 numbers\r\n    if (!features || features.length !== 30) {\r\n      return res.status(400).json({ error: \"Features array must have 30 values.\" });\r\n    }\r\n\r\n    // -------------------------------\r\n    // Step 1: ML prediction using Python\r\n    // -------------------------------\r\n    const pyPath = path.join(process.cwd(), \"models\", \"predict.py\");\r\n\r\n    // Spawn Python process\r\n    const result = spawnSync(\"python\", [pyPath, JSON.stringify(features)], { encoding: \"utf-8\" });\r\n\r\n    if (result.stderr) console.error(result.stderr);\r\n    const prediction = parseInt(result.stdout.trim(), 10); // 0 = Not Fraud, 1 = Fraud\r\n\r\n    // -------------------------------\r\n    // Step 2: Gemini reasoning\r\n    // -------------------------------\r\n    const prompt = `\r\nA credit card transaction has the following features:\r\n${JSON.stringify(features)}\r\n\r\nThe machine learning model predicted:\r\n${prediction === 1 ? \"Fraud\" : \"Not Fraud\"}\r\n\r\nExplain clearly and simply why this transaction might be considered fraudulent or not.\r\n`;\r\n\r\n    const geminiRes = await fetch(\r\n      `https://generativelanguage.googleapis.com/v1beta2/models/gemini-1:generateMessage?key=${GEMINI_API_KEY}`,\r\n      {\r\n        method: \"POST\",\r\n        headers: { \"Content-Type\": \"application/json\" },\r\n        body: JSON.stringify({\r\n          prompt: { messages: [{ author: \"user\", content: prompt }] },\r\n          temperature: 0.6,\r\n          max_output_tokens: 180,\r\n        }),\r\n      }\r\n    );\r\n\r\n    const geminiData = await geminiRes.json();\r\n    const reasoning = geminiData?.candidates?.[0]?.content?.[0]?.text || \"AI reasoning could not be generated.\";\r\n\r\n    res.status(200).json({ prediction, reasoning });\r\n  } catch (err: any) {\r\n    console.error(err);\r\n    res.status(500).json({ error: err.message });\r\n  }\r\n}\r\n"],"names":[],"mappings":";;;;AACA;AACA;;;AAGA,8BAA8B;AAC9B,MAAM,iBAAiB,QAAQ,GAAG,CAAC,UAAU;AAE9B,eAAe,QAAQ,GAAmB,EAAE,GAAoB;IAC7E,IAAI,IAAI,MAAM,KAAK,QAAQ,OAAO,IAAI,MAAM,CAAC,KAAK,GAAG;IAErD,IAAI;QACF,MAAM,EAAE,QAAQ,EAAE,GAAG,IAAI,IAAI,EAAE,6BAA6B;QAC5D,IAAI,CAAC,YAAY,SAAS,MAAM,KAAK,IAAI;YACvC,OAAO,IAAI,MAAM,CAAC,KAAK,IAAI,CAAC;gBAAE,OAAO;YAAsC;QAC7E;QAEA,kCAAkC;QAClC,qCAAqC;QACrC,kCAAkC;QAClC,MAAM,SAAS,4GAAI,CAAC,IAAI,CAAC,QAAQ,GAAG,IAAI,UAAU;QAElD,uBAAuB;QACvB,MAAM,SAAS,IAAA,gIAAS,EAAC,UAAU;YAAC;YAAQ,KAAK,SAAS,CAAC;SAAU,EAAE;YAAE,UAAU;QAAQ;QAE3F,IAAI,OAAO,MAAM,EAAE,QAAQ,KAAK,CAAC,OAAO,MAAM;QAC9C,MAAM,aAAa,SAAS,OAAO,MAAM,CAAC,IAAI,IAAI,KAAK,2BAA2B;QAElF,kCAAkC;QAClC,2BAA2B;QAC3B,kCAAkC;QAClC,MAAM,SAAS,CAAC;;AAEpB,EAAE,KAAK,SAAS,CAAC,UAAU;;;AAG3B,EAAE,eAAe,IAAI,UAAU,YAAY;;;AAG3C,CAAC;QAEG,MAAM,YAAY,MAAM,MACtB,CAAC,sFAAsF,EAAE,gBAAgB,EACzG;YACE,QAAQ;YACR,SAAS;gBAAE,gBAAgB;YAAmB;YAC9C,MAAM,KAAK,SAAS,CAAC;gBACnB,QAAQ;oBAAE,UAAU;wBAAC;4BAAE,QAAQ;4BAAQ,SAAS;wBAAO;qBAAE;gBAAC;gBAC1D,aAAa;gBACb,mBAAmB;YACrB;QACF;QAGF,MAAM,aAAa,MAAM,UAAU,IAAI;QACvC,MAAM,YAAY,YAAY,YAAY,CAAC,EAAE,EAAE,SAAS,CAAC,EAAE,EAAE,QAAQ;QAErE,IAAI,MAAM,CAAC,KAAK,IAAI,CAAC;YAAE;YAAY;QAAU;IAC/C,EAAE,OAAO,KAAU;QACjB,QAAQ,KAAK,CAAC;QACd,IAAI,MAAM,CAAC,KAAK,IAAI,CAAC;YAAE,OAAO,IAAI,OAAO;QAAC;IAC5C;AACF"}}]
}